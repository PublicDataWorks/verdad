# Supabase & Postgres Schema

## Supabase & Postgres Schema

VERDAD utilizes Supabase (Postgres) as its central data store, managing everything from raw audio metadata and AI processing states to user-generated labels and collaborative comments. The schema is designed to support a multi-stage asynchronous pipeline orchestrated by Prefect.

### Core Database Tables

The database is organized into three main functional areas: Pipeline Management, Analysis & Results, and Collaboration.

#### Pipeline Management
*   **`audio_files`**: Tracks raw audio recordings from radio stations.
    *   `id`: UUID (Primary Key)
    *   `status`: Current state (e.g., `pending`, `reserved`, `completed`, `error`)
    *   `radio_station_code`: Identifier for the station (e.g., `WLEL - 94.3 FM`)
    *   `file_path`: Storage location of the raw audio.
*   **`stage_1_llm_responses`**: Stores initial screening results from Gemini (1.5 or 2.5 Flash).
    *   `audio_file_id`: Foreign key to `audio_files`.
    *   `status`: Processing state for Stage 2 (Audio Clipping).
*   **`prompt_versions`**: Manages the versioning of LLM prompts used across different stages.
    *   `stage`: The pipeline stage (1-5).
    *   `is_active`: Boolean flag to determine which prompt is currently in use.

#### Analysis & Results
*   **`snippets`**: The primary entity for disinformation analysis, representing a specific flagged segment of audio.
    *   `id`: UUID (Primary Key)
    *   `status`: Current review state (e.g., `ready_for_review`, `processing`).
    *   `previous_analysis`: JSONB field containing the structured output from Stage 3 models (Claims, Emotional Tone, Political Leaning).
*   **`labels`**: Global repository of disinformation categories (e.g., "Conspiracy Theory").
    *   `english`: Label name in English.
    *   `spanish`: Label name in Spanish.
*   **`snippet_labels`**: A join table associating multiple labels with a single snippet.

#### Collaboration & System
*   **`comments`**: Stores discussions between researchers, synced from Liveblocks.
    *   `thread_id`, `room_id`: Identifiers for the collaborative session.
    *   `body`: JSONB content of the comment.
*   **`comment_reactions`**: Tracks user reactions (emojis) to specific comments.
*   **`email_template`**: Stores HTML templates for system notifications (e.g., @mentions).

### Custom RPC Functions

The processing pipeline uses Postgres Stored Procedures (RPCs) to handle atomic operations and task "reservation" to prevent multiple workers from processing the same data simultaneously.

| Function | Description |
| :--- | :--- |
| `fetch_a_new_audio_file_and_reserve_it` | Retrieves a pending audio file and sets status to `reserved`. |
| `fetch_a_new_snippet_and_reserve_it` | Grabs a snippet ready for Stage 3 analysis. |
| `fetch_a_ready_for_review_snippet_and_reserve_it` | Grabs a snippet ready for Stage 4 manual review. |

### Structured Data (JSONB)

The `snippets.previous_analysis` column stores complex, nested data generated by the Stage 3 AI models. This structured data includes:

```json
{
  "transcription": "Original text...",
  "translation": "English translation...",
  "analysis": {
    "claims": [
      {
        "quote": "The claim text",
        "evidence": "Fact-check evidence",
        "score": 85
      }
    ],
    "political_leaning": {
      "score": -0.5,
      "explanation": "Analysis of rhetoric"
    }
  },
  "emotional_tone": [
    {
      "emotion": {"english": "Fear", "spanish": "Miedo"},
      "intensity": 90
    }
  ]
}
```

### Accessing the Database

#### Python (Processing Pipeline)
The pipeline uses the `SupabaseClient` wrapper found in `src/processing_pipeline/supabase_utils.py` to interact with the schema:

```python
from processing_pipeline.supabase_utils import SupabaseClient

client = SupabaseClient(url, key)

# Reserve a task from the queue
audio_file = client.get_a_new_audio_file_and_reserve_it()

# Update snippet status
client.set_snippet_status(snippet_id, "completed")
```

#### TypeScript (Server)
The backend server interacts with the collaboration tables using the standard Supabase JS client:

```typescript
import { createClient } from "@supabase/supabase-js";

const supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_SERVICE_ROLE_KEY);

// Upserting comments from a webhook or sync service
const { error } = await supabase
  .from("comments")
  .upsert({ id: commentId, body: content });
```

### Safety and Content Moderation
The system includes configuration for Gemini's safety settings, stored indirectly through pipeline logic but applied to content that influences the database records. Categories include `HATE_SPEECH`, `HARASSMENT`, and `CIVIC_INTEGRITY`. Data flagged as violating these during analysis is still stored but marked with appropriate metadata for researcher review.
